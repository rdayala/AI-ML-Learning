{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 1\n",
    "## Experiment 3\n",
    "### Home work -- Optionally @ Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Source\n",
    "In this experiment, we will use famous Iris data set.\n",
    "https://archive.ics.uci.edu/ml/datasets/iris\n",
    "\n",
    "### Objective\n",
    "To use the kNN classifier for multi-class classification.\n",
    "\n",
    "#### Dataset Information:\n",
    "\n",
    "This is perhaps the best known database to be found in the pattern recognition literature. Fisher's paper is a classic in the field and is referenced frequently to this day. \n",
    "\n",
    "The data set contains 3 classes of 50 instances each, where each class refers to a type of iris plant. One class is linearly separable from the other 2; the latter are NOT linearly separable from each other. \n",
    "\n",
    "\n",
    "### Data Attributes\n",
    "\n",
    "  1. sepal length in cm \n",
    "  2. sepal width in cm \n",
    "  3. petal length in cm \n",
    "  4. petal width in cm \n",
    "  5. class: \n",
    "     -- Iris Setosa  \n",
    "     -- Iris Versicolour \n",
    "     -- Iris Virginica\n",
    "\n",
    "### Predicted attribute\n",
    "class of iris plant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.read_csv(\"../Datasets/bezdekIris.data\", header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While we cannot do much plotting in three dimensions, it may be worth plotting two attributes at a time and exploring this dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import collections\n",
    "def dist(a, b):\n",
    "    sqSum = 0\n",
    "    for i in range(len(a)):\n",
    "        sqSum += (a[i] - b[i]) ** 2\n",
    "    return math.sqrt(sqSum)\n",
    "# ------------------------------------------------ #\n",
    "# We are assuming that the label is the last field #\n",
    "# If not, munge the data to make it so!            #\n",
    "# ------------------------------------------------ #\n",
    "def kNN(k, train, given):\n",
    "    distances = []\n",
    "    for t in train:\n",
    "        distances.append((dist(t[:-1], given), t[-1]))\n",
    "    distances.sort()\n",
    "    return distances[:k]\n",
    "\n",
    "def kNN_classify(k, train, given):\n",
    "    tally = collections.Counter()\n",
    "    for nn in kNN(k, train, given):\n",
    "        tally.update(nn[-1])\n",
    "    return tally.most_common(1)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1** :: Split the dataset into 120 + 30, for training and testing. Use K = 5 and Euclidean distance. Find the accuracy (as percentage) on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Set the three iris as 0, 1, 2\n",
    "# Iris Setosa -> 0\n",
    "# Iris-versicolor -> 1\n",
    "# Iris-virginica -> 2\n",
    "\n",
    "def pre_process_iris(iris):\n",
    "    iris = iris.strip().lower()\n",
    "    if iris == 'iris-setosa':\n",
    "        return 'S'\n",
    "    elif iris == 'iris-versicolor':\n",
    "        return 'E'\n",
    "    elif iris == 'iris-virginica':\n",
    "        return 'I'\n",
    "    else:\n",
    "        return 'X'\n",
    "\n",
    "irisData = pd.read_csv(\"../Datasets/bezdekIris.data\", header=None, converters={4:pre_process_iris})\n",
    "irisData.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Set the three iris as 0, 1, 2\n",
    "# Iris Setosa -> 0\n",
    "# Iris-versicolor -> 1\n",
    "# Iris-virginica -> 2\n",
    "\n",
    "def pre_process_iris(iris):\n",
    "    iris = iris.strip().lower()\n",
    "    if iris == 'iris-setosa':\n",
    "        return 'S'\n",
    "    elif iris == 'iris-versicolor':\n",
    "        return 'E'\n",
    "    elif iris == 'iris-virginica':\n",
    "        return 'I'\n",
    "    else:\n",
    "        return 'X'\n",
    "\n",
    "irisData = pd.read_csv(\"../Datasets/bezdekIris.data\", header=None, converters={4:pre_process_iris})\n",
    "\n",
    "TRAIN_TEST_RATIO = 0.8\n",
    "picker = list(range(irisData.shape[0]))\n",
    "random.shuffle(picker)       ### randomly shuffle the data\n",
    "trainMax = int(len(picker) * TRAIN_TEST_RATIO)\n",
    "train = []\n",
    "test = []\n",
    "for pick in picker[:trainMax]:\n",
    "    train.append(list(irisData.values[pick]))         ### select 80% of data to be used as training set\n",
    "for pick in picker[trainMax:]:\n",
    "    test.append(list(irisData.values[pick]))       ### select 20% of data to be used as test set\n",
    "\n",
    "results = []\n",
    "for i, t in enumerate(test):\n",
    "    results.append(kNN_classify(5, train, t)[0] == test[i][-1])\n",
    "print(results.count(True), \"are correct\")\n",
    "correctPredicted = results.count(True)\n",
    "totalTestData = len(test)\n",
    "accuracy = (correctPredicted / totalTestData) * 100\n",
    "print('The accuracy is ' + str(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2** :: Repeat the above (creating random partitions and evaluating the performance) 5 times. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Set the three iris as 0, 1, 2\n",
    "# Iris Setosa -> 0\n",
    "# Iris-versicolor -> 1\n",
    "# Iris-virginica -> 2\n",
    "\n",
    "def pre_process_iris(iris):\n",
    "    iris = iris.strip().lower()\n",
    "    if iris == 'iris-setosa':\n",
    "        return 'S'\n",
    "    elif iris == 'iris-versicolor':\n",
    "        return 'E'\n",
    "    elif iris == 'iris-virginica':\n",
    "        return 'I'\n",
    "    else:\n",
    "        return 'X'\n",
    "\n",
    "irisData = pd.read_csv(\"../Datasets/bezdekIris.data\", header=None, converters={4:pre_process_iris})\n",
    "\n",
    "j = 0\n",
    "accuracyList = []\n",
    "avgAccuracy = 0\n",
    "\n",
    "for j in range(0, 5):\n",
    "    TRAIN_TEST_RATIO = 0.8\n",
    "    picker = list(range(irisData.shape[0]))\n",
    "    random.shuffle(picker)       ### randomly shuffle the data\n",
    "    trainMax = int(len(picker) * TRAIN_TEST_RATIO)\n",
    "    train = []\n",
    "    test = []\n",
    "    for pick in picker[:trainMax]:\n",
    "        train.append(list(irisData.values[pick]))         ### select 80% of data to be used as training set\n",
    "    for pick in picker[trainMax:]:\n",
    "        test.append(list(irisData.values[pick]))       ### select 20% of data to be used as test set\n",
    "\n",
    "    results = []\n",
    "    for i, t in enumerate(test):\n",
    "        results.append(kNN_classify(5, train, t)[0] == test[i][-1])\n",
    "    print(results.count(True), \"are correct\")\n",
    "    correctPredicted = results.count(True)\n",
    "    totalTestData = len(test)\n",
    "    accuracy = (correctPredicted / totalTestData) * 100\n",
    "    print('The accuracy is ' + str(accuracy))\n",
    "    accuracyList.append(accuracy)\n",
    "    avgAccuracy += accuracy\n",
    "    \n",
    "avgAccuracy = avgAccuracy / len(accuracyList)\n",
    "print('The average accuracy is ' + str(avgAccuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3** :: Vary K from 3 to 11 and find the best K."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Set the three iris as 0, 1, 2\n",
    "# Iris Setosa -> 0\n",
    "# Iris-versicolor -> 1\n",
    "# Iris-virginica -> 2\n",
    "\n",
    "def pre_process_iris(iris):\n",
    "    iris = iris.strip().lower()\n",
    "    if iris == 'iris-setosa':\n",
    "        return 'S'\n",
    "    elif iris == 'iris-versicolor':\n",
    "        return 'E'\n",
    "    elif iris == 'iris-virginica':\n",
    "        return 'I'\n",
    "    else:\n",
    "        return 'X'\n",
    "\n",
    "irisData = pd.read_csv(\"../Datasets/bezdekIris.data\", header=None, converters={4:pre_process_iris})\n",
    "\n",
    "j = 0\n",
    "k = 3\n",
    "\n",
    "for k in range(3, 12):\n",
    "    accuracyList = []\n",
    "    avgAccuracy = 0\n",
    "    \n",
    "    for j in range(0, 5):\n",
    "        TRAIN_TEST_RATIO = 0.8\n",
    "        picker = list(range(irisData.shape[0]))\n",
    "        random.shuffle(picker)       ### randomly shuffle the data\n",
    "        trainMax = int(len(picker) * TRAIN_TEST_RATIO)\n",
    "        train = []\n",
    "        test = []\n",
    "        for pick in picker[:trainMax]:\n",
    "            train.append(list(irisData.values[pick]))         ### select 80% of data to be used as training set\n",
    "        for pick in picker[trainMax:]:\n",
    "            test.append(list(irisData.values[pick]))       ### select 20% of data to be used as test set\n",
    "\n",
    "        results = []\n",
    "        for i, t in enumerate(test):\n",
    "            results.append(kNN_classify(5, train, t)[0] == test[i][-1])\n",
    "        print(results.count(True), \"are correct\")\n",
    "        correctPredicted = results.count(True)\n",
    "        totalTestData = len(test)\n",
    "        accuracy = (correctPredicted / totalTestData) * 100\n",
    "        print('The accuracy is ' + str(accuracy))\n",
    "        accuracyList.append(accuracy)\n",
    "        avgAccuracy += accuracy\n",
    "        # Reset j\n",
    "        j = 0\n",
    "\n",
    "    avgAccuracy = avgAccuracy / len(accuracyList)\n",
    "    print('The average accuracy for k = ' + str(k) + ' is ' + str(avgAccuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
